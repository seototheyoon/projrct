{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef912a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 라이브러리 임포트 및 기본 설정\n",
    "# AS usual, a bit of setup\n",
    "# If you need other libraries, you should import the libraries.\n",
    "\n",
    "import os, sys\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Set the device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee9330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Cutout 클래스 정의\n",
    "transforms_cifar10 = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                 ])\n",
    "transforms_cifar10_training = transforms.Compose([\n",
    "                                  transforms.RandomCrop(32, padding=4),\n",
    "                                  transforms.RandomHorizontalFlip(),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                        (0.5, 0.5, 0.5))\n",
    "                                 ])\n",
    "# Train dataset\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms_cifar10)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "#배치 사이즈 바꿔도 됨, 셔플은 학습순서 기억하지 못하도록 하기 위해 사용.\n",
    "\n",
    "# Test dataset\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms_cifar10)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
    "#배치 사이즈 바꿔도 됨, test는 셔플 필요없음 .\n",
    "\n",
    "# Classes of CIFAR-10 dataset\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4df8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 데이터셋 및 증강 설정\n",
    "# AS usual, a bit of setup\n",
    "# If you need other libraries, you should import the libraries.\n",
    "\n",
    "import os, sys\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import AutoAugment, AutoAugmentPolicy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std = (0.2023, 0.1994, 0.2010)\n",
    "# Set the device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "transforms_cifar10 = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                 ])\n",
    "transforms_cifar10_training = transforms.Compose([\n",
    "                                  transforms.RandomCrop(32, padding=4),\n",
    "                                  transforms.RandomHorizontalFlip(),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                        (0.5, 0.5, 0.5))\n",
    "                                 ])\n",
    "# Train dataset\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms_cifar10)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "#배치 사이즈 바꿔도 됨, 셔플은 학습순서 기억하지 못하도록 하기 위해 사용.\n",
    "\n",
    "# Test dataset\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms_cifar10)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
    "#배치 사이즈 바꿔도 됨, test는 셔플 필요없음 .\n",
    "\n",
    "# Classes of CIFAR-10 dataset\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "# Examples of dataset\n",
    "\n",
    "def imshow(img):\n",
    "  img = img /2 + 0.5\n",
    "  npimg = img.numpy()\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "imgs, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(imgs))\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "# ResNet110 Model\n",
    "# 모델 설명: https://pseudo-lab.github.io/pytorch-guide/docs/ch03-1.html\n",
    "#Input(3x32x32)\n",
    "#↓ Conv3x3 (16)\n",
    "#↓ Layer1: 18 x [Conv3x3(16) → Conv3x3(16)]\n",
    "#↓ Layer2: 18 x [Conv3x3(32) → Conv3x3(32)] (stride=2)\n",
    "#↓ Layer3: 18 x [Conv3x3(64) → Conv3x3(64)] (stride=2)\n",
    "#↓ GlobalAvgPool\n",
    "#↓ FC(64 → 10)\n",
    "#↓ Softmax\n",
    "class Cutout(object):\n",
    "    def __init__(self, n_holes=1, length=16):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        import numpy as np\n",
    "        import torch\n",
    "        h, w = img.size(1), img.size(2)\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "        for _ in range(self.n_holes):\n",
    "            y, x = np.random.randint(h), np.random.randint(w)\n",
    "            y1, y2 = np.clip(y - self.length // 2, 0, h), np.clip(y + self.length // 2, 0, h)\n",
    "            x1, x2 = np.clip(x - self.length // 2, 0, w), np.clip(x + self.length // 2, 0, w)\n",
    "            mask[y1:y2, x1:x2] = 0.\n",
    "        mask = torch.from_numpy(mask).expand_as(img)\n",
    "        return img * mask\n",
    "\n",
    "cutout = Cutout(n_holes=1, length=16)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    AutoAugment(policy=AutoAugmentPolicy.CIFAR10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: cutout(x)),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_planes),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_planes)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != out_planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_planes)\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.block(x) + self.shortcut(x))\n",
    "\n",
    "class ResNet56(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_planes = 16\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.layer1 = self._make_layer(16, 9)\n",
    "        self.layer2 = self._make_layer(32, 9, stride=2)\n",
    "        self.layer3 = self._make_layer(64, 9, stride=2)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, out_planes, blocks, stride=1):\n",
    "        strides = [stride] + [1]*(blocks - 1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(BasicBlock(self.in_planes, out_planes, s))\n",
    "            self.in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.pool(x).view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "net = ResNet56().to(device)\n",
    "#SGD + Momentum + CosineAnnealingLR 조합\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 보통 CosineAnnealing은 초기에 큰 learning rate를 사용\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "# CosineAnnealingLR 스케줄러로 변경\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "# Train the model 그대로 사용\n",
    "epochs = 200  # number of epochs 바꾸기!!!\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    loss_tmp = 0.0\n",
    "    epoch_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, start=0):\n",
    "        # Load the data\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Estimate the output using the network\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # Calculate the loss between the output of the network and label\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Optimize the network\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_tmp += loss.data\n",
    "        epoch_loss += loss.data\n",
    "\n",
    "        if i % 5000 == 4999:    # Print loss every 5000 mini-batches\n",
    "            print('[Epoch - %d, Iteration - %5d] Loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, loss_tmp / (i+1)))\n",
    "            loss_tmp = 0.0\n",
    "\n",
    "    # Update the learning rate according to the learnig rate scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print the epoch loss\n",
    "    print('[Epoch - %d] Loss: %.3f' %(epoch + 1, epoch_loss / (i+1)))\n",
    "\n",
    "print('Finished Training')\n",
    "# Test the trained model with sample\n",
    "\n",
    "dataiter_test = iter(testloader)\n",
    "img_test, labels_test = next(dataiter_test)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(img_test))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels_test[j]] for j in range(4)))\n",
    "\n",
    "img_test = img_test.to(device)\n",
    "labels_test = labels_test.to(device)\n",
    "\n",
    "# Prediction\n",
    "outputs_test = net(img_test)\n",
    "_, predicted = torch.max(outputs_test.data, 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n",
    "# Test the trained model with overall test dataset\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    # Load the data\n",
    "    inputs_test, labels_test = data\n",
    "    inputs_test = inputs_test.to(device)\n",
    "    labels_test = labels_test.to(device)\n",
    "\n",
    "    # Estimate the output using the trained network\n",
    "    outputs_test = net(inputs_test)\n",
    "    _, predicted = torch.max(outputs_test.data, 1)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    total += labels_test.size(0)\n",
    "    correct += (predicted == labels_test).sum()\n",
    "\n",
    "# Final accuracy\n",
    "print('Accuracy of the network on the 10,000 test images: %.1f %%' % (100 * correct / total))\n",
    "\n",
    "\n",
    "## [SimpleNet / Training 5 epochs] Accuracy of the network on the 10,000 test images: 9 %\n",
    "## [VGG11 / Training 5 epochs] Accuracy of the network on the 10,000 test images: 12 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1933892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. PreActResNet56 모델 정의\n",
    "# Train data preprocessing (with augmentation + scaling)\n",
    "transforms_cifar10_train = transforms.Compose([\n",
    "    transforms.Resize((36, 36)),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.5)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Test data preprocessing (with scaling only)\n",
    "transforms_cifar10 = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                 ])\n",
    "\n",
    "# Train dataset\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms_cifar10)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "#배치 사이즈 바꿔도 됨, 셔플은 학습순서 기억하지 못하도록 하기 위해 사용.\n",
    "\n",
    "# Test dataset\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms_cifar10)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
    "#배치 사이즈 바꿔도 됨, test는 셔플 필요없음 .\n",
    "\n",
    "# Classes of CIFAR-10 dataset\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "# Examples of dataset\n",
    "\n",
    "def imshow(img):\n",
    "  img = img /2 + 0.5\n",
    "  npimg = img.numpy()\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "imgs, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(imgs))\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "# Pre-activation Basic Block\n",
    "\n",
    "class PreActBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(PreActBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != out_planes:\n",
    "            self.shortcut = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(self.relu1(self.bn1(x)))\n",
    "        out = self.conv2(self.relu2(self.bn2(out)))\n",
    "        out += self.shortcut(x)\n",
    "        return out\n",
    "\n",
    "# ResNet with PreActBlocks\n",
    "\n",
    "class PreActResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(PreActResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.bn = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        layers = [block(self.in_planes, planes, stride)]\n",
    "        self.in_planes = planes\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.relu(self.bn(out))  # 마지막 pre-activation\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "# Train/Test Functions\n",
    "\n",
    "def train(model, criterion, optimizer, trainloader, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, targets in trainloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch}, Loss: {total_loss:.3f}\")\n",
    "\n",
    "def test(model, testloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in testloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "    return acc\n",
    "\n",
    "net = PreActResNet(PreActBlock, [9, 9, 9]).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "# 학습 결과 저장용 리스트\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Train the model\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    loss_tmp = 0.0\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(trainloader, start=0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_tmp += loss.data.item()\n",
    "        epoch_loss += loss.data.item()\n",
    "\n",
    "        if i % 5000 == 4999:\n",
    "            print('[Epoch - %d, Iteration - %5d] Loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, loss_tmp / (i+1)))\n",
    "            loss_tmp = 0.0\n",
    "\n",
    "    # 평균 train loss 저장\n",
    "    avg_train_loss = epoch_loss / (i + 1)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # learning rate scheduler 업데이트\n",
    "    scheduler.step()\n",
    "\n",
    "    # 검증 정확도 계산\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    val_acc = 100. * correct / total\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    # 출력\n",
    "    print('[Epoch - %d] Loss: %.3f | Val Acc: %.2f%%' %\n",
    "          (epoch + 1, avg_train_loss, val_acc))\n",
    "\n",
    "print('Finished Training')\n",
    "train_losses = [\n",
    "    1.996, 1.656, 1.473, 1.321, 1.179, 1.073, 0.991, 0.914, 0.852, 0.798,\n",
    "    0.701, 0.667, 0.633, 0.601, 0.573, 0.540, 0.505, 0.479, 0.448, 0.424,\n",
    "    0.333, 0.303, 0.279, 0.262, 0.239, 0.224, 0.208, 0.193, 0.177, 0.171,\n",
    "    0.126, 0.111, 0.100, 0.094, 0.086, 0.081, 0.077, 0.073, 0.067, 0.064,\n",
    "    0.054, 0.053, 0.053, 0.049, 0.046, 0.046, 0.045, 0.045, 0.043, 0.042,\n",
    "    0.039, 0.037, 0.037, 0.036, 0.037, 0.035, 0.035, 0.036, 0.035, 0.033,\n",
    "    0.033, 0.032, 0.032, 0.032, 0.030, 0.032, 0.030, 0.031, 0.031, 0.031,\n",
    "    0.031, 0.030, 0.030, 0.030, 0.030, 0.030, 0.029, 0.029, 0.030, 0.029,\n",
    "    0.029, 0.029, 0.029, 0.029, 0.029, 0.029, 0.029, 0.029, 0.029, 0.030,\n",
    "    0.029, 0.028, 0.029, 0.029, 0.028, 0.027, 0.029, 0.029, 0.028, 0.028,\n",
    "    0.028, 0.027, 0.027, 0.028, 0.029, 0.029, 0.028, 0.029, 0.029, 0.029,\n",
    "    0.029, 0.029, 0.029, 0.028, 0.028, 0.029, 0.029, 0.029, 0.029, 0.028,\n",
    "    0.028, 0.029, 0.029, 0.029, 0.029, 0.029, 0.028, 0.028, 0.028, 0.028,\n",
    "    0.029, 0.029, 0.029, 0.029, 0.028, 0.028, 0.028, 0.028, 0.028, 0.028,\n",
    "    0.028, 0.028, 0.028, 0.028, 0.028, 0.028, 0.028, 0.029, 0.029, 0.030,\n",
    "    0.028, 0.028, 0.028, 0.028, 0.028, 0.029, 0.029, 0.029, 0.028, 0.028,\n",
    "    0.028, 0.028, 0.028, 0.028, 0.030, 0.027, 0.026, 0.028, 0.027, 0.029,\n",
    "    0.028, 0.028, 0.028, 0.028, 0.028, 0.028, 0.028, 0.028, 0.029, 0.027,\n",
    "    0.028, 0.029, 0.028\n",
    "]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "min_len = min(len(epochs), len(train_losses))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs[:min_len], train_losses[:min_len], marker='o', color='orange')\n",
    "plt.title(\"Training Loss over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.grid(True)\n",
    "plt.xticks(range(0, min_len + 1, 10))\n",
    "plt.show()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (1) Epoch 리스트\n",
    "epochs = list(range(1, 196))\n",
    "\n",
    "# (2) Validation Accuracy 리스트 (% 단위 그대로 사용)\n",
    "val_accuracies = [\n",
    "    33.93, 41.29, 47.49, 52.81, 56.01, 55.95, 59.60, 65.50, 66.02, 67.77,\n",
    "    68.91, 71.67, 70.41, 71.06, 70.45, 71.50, 67.30, 71.86, 72.19, 72.16,\n",
    "    73.47, 73.82, 73.70, 72.88, 72.63, 72.47, 72.26, 71.46, 73.11, 71.95,\n",
    "    72.69, 72.99, 72.80, 72.40, 72.64, 72.74, 72.39, 71.89, 72.44, 72.27,\n",
    "    71.92, 72.14, 71.95, 72.12, 72.18, 71.91, 72.15, 71.81, 72.25, 72.15,\n",
    "    71.82, 71.98, 72.18, 71.97, 71.90, 71.88, 71.91, 71.59, 71.94, 71.82,\n",
    "    71.84, 71.76, 71.92, 71.85, 71.76, 71.67, 71.82, 71.88, 71.80, 71.76,\n",
    "    71.72, 71.72, 71.67, 71.72, 71.77, 71.84, 71.44, 71.73, 71.65, 71.63,\n",
    "    71.83, 71.75, 71.61, 71.49, 71.77, 71.63, 71.69, 71.60, 71.75, 71.75,\n",
    "    71.72, 71.71, 71.65, 71.73, 71.45, 71.53, 71.74, 71.43, 71.63, 71.78,\n",
    "    71.54, 71.74, 71.66, 71.77, 71.82, 71.66, 71.80, 71.75, 71.63, 71.68,\n",
    "    71.77, 71.47, 71.70, 71.68, 71.69, 71.49, 71.79, 71.59, 71.68, 71.61,\n",
    "    71.67, 71.69, 71.84, 71.66, 71.73, 71.67, 71.56, 71.94, 71.71, 71.59,\n",
    "    71.57, 71.50, 71.62, 71.65, 71.73, 71.62, 71.66, 71.62, 71.72, 71.70,\n",
    "    71.86, 71.80, 71.91, 71.65, 71.71, 71.62, 71.69, 71.65, 71.76, 71.58,\n",
    "    71.68, 71.72, 71.66, 71.74, 71.56, 71.64, 71.59, 71.61, 71.74, 71.75,\n",
    "    71.70, 71.78, 71.54, 71.79, 71.71, 71.67, 71.70, 71.66, 71.61, 71.77,\n",
    "    71.69, 71.61, 71.49, 71.73, 71.82, 71.72, 71.66, 71.57, 71.61, 71.30,\n",
    "    71.65, 71.70, 71.75, 71.66, 71.76, 71.60, 71.72, 71.49, 71.71, 71.84,\n",
    "    71.53, 71.61, 71.66\n",
    "]\n",
    "\n",
    "# (3) 시각화\n",
    "min_len = min(len(epochs), len(val_accuracies))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs[:min_len], val_accuracies[:min_len], marker='o')\n",
    "plt.title(\"Validation Accuracy over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation Accuracy (%)\")\n",
    "plt.grid(True)\n",
    "plt.xticks(range(0, min_len + 1, 10))\n",
    "plt.ylim(30, 75)\n",
    "plt.show()\n",
    "# Test the trained model with sample\n",
    "\n",
    "dataiter_test = iter(testloader)\n",
    "img_test, labels_test = next(dataiter_test)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(img_test))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels_test[j]] for j in range(4)))\n",
    "\n",
    "img_test = img_test.to(device)\n",
    "labels_test = labels_test.to(device)\n",
    "\n",
    "# Prediction\n",
    "outputs_test = net(img_test)\n",
    "_, predicted = torch.max(outputs_test.data, 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n",
    "# Test the trained model with overall test dataset\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    # Load the data\n",
    "    inputs_test, labels_test = data\n",
    "    inputs_test = inputs_test.to(device)\n",
    "    labels_test = labels_test.to(device)\n",
    "\n",
    "    # Estimate the output using the trained network\n",
    "    outputs_test = net(inputs_test)\n",
    "    _, predicted = torch.max(outputs_test.data, 1)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    total += labels_test.size(0)\n",
    "    correct += (predicted == labels_test).sum()\n",
    "\n",
    "# Final accuracy\n",
    "print('Accuracy of the network on the 10,000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "\n",
    "## [SimpleNet / Training 5 epochs] Accuracy of the network on the 10,000 test images: 9 %\n",
    "## [VGG11 / Training 5 epochs] Accuracy of the network on the 10,000 test images: 12 %\n"
   ]
  }
}
